{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "practical-public",
   "metadata": {},
   "source": [
    "### Training a Model Locally\n",
    "Mico Ellerich M. Comia\n",
    "\n",
    "---\n",
    "\n",
    "- SELECT 2 MACHINE LEARNING ALGORITHMS \n",
    "- FOR EACH OF THE ALGORITHMS\n",
    "    - PERFORM TRAINING ON THE TRAINING DATASET\n",
    "    - EVALUATE ON THE VALIDATION DATASET\n",
    "    - TEST THE TRAINED MODEL ON THE TEST SET\n",
    "    - SAVE THE MODEL USING JOBLIB (OR ALTERNATIVE)\n",
    "- COMPARE THE “PERFORMANCE” OF THE 2 MODELS USING THE EVALUATION METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comparable-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-colon",
   "metadata": {},
   "source": [
    "### I. Import dataset splits\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educational-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  pd.read_csv('data/X_train.csv')\n",
    "X_test =  pd.read_csv('data/X_test.csv') \n",
    "X_val = pd.read_csv('data/X_val.csv') \n",
    "y_train =  pd.read_csv('data/y_train.csv') \n",
    "y_test =  pd.read_csv('data/y_test.csv') \n",
    "y_val = pd.read_csv('data/y_val.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-trigger",
   "metadata": {},
   "source": [
    "### II. Select 2 ML Algorithms\n",
    "    - PERFORM TRAINING ON THE TRAINING DATASET\n",
    "    - EVALUATE ON THE VALIDATION DATASET\n",
    "    - TEST THE TRAINED MODEL ON THE TEST SET\n",
    "    - SAVE THE MODEL USING JOBLIB (OR ALTERNATIVE)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-issue",
   "metadata": {},
   "source": [
    "#### Training on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "native-volunteer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "\n",
    "svm_model = SVC(kernel='rbf')  \n",
    "svm_model.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-stranger",
   "metadata": {},
   "source": [
    "#### Evaluate on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "significant-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.955\n",
      "Precision: 0.93\n",
      "Recall: 0.9789473684210527\n"
     ]
    }
   ],
   "source": [
    "svm_pred_val =  svm_model.predict(X_val)\n",
    "\n",
    "svm_val_acc = metrics.accuracy_score(y_val, svm_pred_val)\n",
    "svm_val_prec = metrics.precision_score(y_val, svm_pred_val)\n",
    "svm_val_rec = metrics.recall_score(y_val, svm_pred_val)\n",
    "\n",
    "print(f\"Accuracy: {svm_val_acc}\")\n",
    "print(f\"Precision: {svm_val_prec}\")\n",
    "print(f\"Recall: {svm_val_rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-adventure",
   "metadata": {},
   "source": [
    "#### Testing on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "circular-basketball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.965\n",
      "Precision: 0.9468085106382979\n",
      "Recall: 0.978021978021978\n"
     ]
    }
   ],
   "source": [
    "svm_pred_test =  svm_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, svm_pred_test))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, svm_pred_test))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, svm_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-nightlife",
   "metadata": {},
   "source": [
    "#### Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "north-launch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/svm_0520-1547.sav']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestr = time.strftime(\"%m%d-%H%M\")\n",
    "\n",
    "# SVM model saving\n",
    "filename = 'model/logistic_' + timestr + '.sav'\n",
    "joblib.dump(logistic_model, filename)\n",
    "\n",
    "# SVM model saving\n",
    "filename = 'model/svm_' + timestr + '.sav'\n",
    "joblib.dump(svm_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-tracker",
   "metadata": {},
   "source": [
    "### III. Comparison of models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-registrar",
   "metadata": {},
   "source": [
    "Based on the evaluation metrics, the better model between SVM and Logistic Regression is the SVM model. On the test set, the accuracy, precision, and recall of the SVM model is higher by 8%, 10.7%, and 5.5%, respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
